{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950b2909-18bb-42f9-bad0-47dae9b6760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c072d950-fb92-4e7d-859b-b8d6cba99179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CloudDetect.util import read_off, visualise\n",
    "from CloudDetect.transform import PointCloudSample, Normalise, Tensor\n",
    "from CloudDetect.models import PointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea590bb-ad5f-43ea-9da9-77a34e6fd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "metadata = pd.read_csv('data/metadata_modelnet40.csv')\n",
    "all_data_files = glob.glob('**/*.off',recursive=True)\n",
    "all_data_files = set(['/'.join(x.split('/')[2:]) for x in all_data_files])\n",
    "metadata = metadata[metadata['object_path'].map(lambda x: x in all_data_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988e26d5-c0f2-41b5-877f-fa582f143a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = ROOT + metadata['object_path'].iloc[-4465]\n",
    "#verts, faces = read_off(open(file))\n",
    "#fig = visualise(verts)\n",
    "\n",
    "#new_verts = Normalise('max')(PointCloudSample(2000)(verts))\n",
    "#fig = visualise(new_verts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e74f70-aed3-4762-9bc8-8692c7a8e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_points = 2000\n",
    "input = torch.tensor(np.random.uniform(0,1,(batch_size, 3, n_points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6796be55-dc76-4767-8242-276b4b455795",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet = PointNet(n_points, classes = 10, segment = False)\n",
    "classification_output = pnet(input.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b10600c-7a3c-40df-8359-8742e48129ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e12d78-a3bf-41e3-aac3-ac52fa1a02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(n_sample, norm_how):\n",
    "    composition = [\n",
    "            PointCloudSample(n_sample),\n",
    "            Normalise(norm_how),\n",
    "            Tensor()\n",
    "    ]\n",
    "    return transforms.Compose(composition)\n",
    "\n",
    "def generate_class_mapper(metadata):\n",
    "    class_mapper = {x:i for i,x in enumerate(metadata['class'].unique())}\n",
    "    return class_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "941ab398-c47a-4e30-8e9f-44be96f71107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, metadata, preprocessor, root, class_mapper, one_hot = False):\n",
    "        self.metadata = metadata\n",
    "        self.preprocessor = preprocessor\n",
    "        self.root = root\n",
    "        self.class_mapper = class_mapper\n",
    "        self.one_hot = one_hot\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_instance = metadata.iloc[idx]\n",
    "        class_item = self.class_mapper[data_instance['class']]\n",
    "        if self.one_hot:\n",
    "            class_item = torch.nn.functional.one_hot(torch.tensor(class_item), num_classes=len(self.class_mapper))\n",
    "        file = self.root + data_instance['object_path']\n",
    "        verts, faces = read_off(open(file))\n",
    "        return {'data':self.preprocessor(verts),'category':class_item}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def assign_val_indices(df, target_name, n_splits):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    df['kfold'] = None\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X=df, y=df[target_name].values)):\n",
    "        df.loc[val_idx, 'kfold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb5cb138-c20a-4b98-a109-ba8b5be93950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointNet(n_points, classes = len(class_mapper), segment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6dcfbd40-afa0-4098-9393-1db4d45d7410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metadata_train = metadata[metadata['split'] == 'train']\n",
    "metadata_train = metadata_train.sample(200)# for development\n",
    "metadata_test = metadata[metadata['split'] == 'test']\n",
    "metadata_train = metadata_train.reset_index(drop = True)\n",
    "metadata_test = metadata_test.reset_index(drop = True)\n",
    "assign_val_indices(metadata_train, 'class', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f56ceea6-bce3-4919-a992-ac2acee7bc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>class</th>\n",
       "      <th>split</th>\n",
       "      <th>object_path</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chair_0379</td>\n",
       "      <td>chair</td>\n",
       "      <td>train</td>\n",
       "      <td>chair/train/chair_0379.off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chair_0687</td>\n",
       "      <td>chair</td>\n",
       "      <td>train</td>\n",
       "      <td>chair/train/chair_0687.off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>door_0021</td>\n",
       "      <td>door</td>\n",
       "      <td>train</td>\n",
       "      <td>door/train/door_0021.off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airplane_0116</td>\n",
       "      <td>airplane</td>\n",
       "      <td>train</td>\n",
       "      <td>airplane/train/airplane_0116.off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vase_0343</td>\n",
       "      <td>vase</td>\n",
       "      <td>train</td>\n",
       "      <td>vase/train/vase_0343.off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>cup_0067</td>\n",
       "      <td>cup</td>\n",
       "      <td>train</td>\n",
       "      <td>cup/train/cup_0067.off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>toilet_0022</td>\n",
       "      <td>toilet</td>\n",
       "      <td>train</td>\n",
       "      <td>toilet/train/toilet_0022.off</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>night_stand_0144</td>\n",
       "      <td>night</td>\n",
       "      <td>train</td>\n",
       "      <td>night/train/night_stand_0144.off</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>bookshelf_0378</td>\n",
       "      <td>bookshelf</td>\n",
       "      <td>train</td>\n",
       "      <td>bookshelf/train/bookshelf_0378.off</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>cone_0007</td>\n",
       "      <td>cone</td>\n",
       "      <td>train</td>\n",
       "      <td>cone/train/cone_0007.off</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            object_id      class  split                         object_path  \\\n",
       "0          chair_0379      chair  train          chair/train/chair_0379.off   \n",
       "1          chair_0687      chair  train          chair/train/chair_0687.off   \n",
       "2           door_0021       door  train            door/train/door_0021.off   \n",
       "3       airplane_0116   airplane  train    airplane/train/airplane_0116.off   \n",
       "4           vase_0343       vase  train            vase/train/vase_0343.off   \n",
       "..                ...        ...    ...                                 ...   \n",
       "195          cup_0067        cup  train              cup/train/cup_0067.off   \n",
       "196       toilet_0022     toilet  train        toilet/train/toilet_0022.off   \n",
       "197  night_stand_0144      night  train    night/train/night_stand_0144.off   \n",
       "198    bookshelf_0378  bookshelf  train  bookshelf/train/bookshelf_0378.off   \n",
       "199         cone_0007       cone  train            cone/train/cone_0007.off   \n",
       "\n",
       "    kfold  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "..    ...  \n",
       "195     1  \n",
       "196     2  \n",
       "197     2  \n",
       "198     2  \n",
       "199     2  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1b0bb823-b925-4958-a19d-0e654ac46b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train_val = metadata_train[metadata_train['kfold'] == 0]\n",
    "metadata_train_train = metadata_train[metadata_train['kfold'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a2deee91-616a-4503-bc24-18b37e85bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'data/ModelNet40/'\n",
    "preprocessor = preprocessing(1024, 'max')\n",
    "class_mapper = generate_class_mapper(metadata)\n",
    "cloud_train_dataset = CloudDataset(metadata_train_train, preprocessor, ROOT, class_mapper)\n",
    "cloud_val_dataset = CloudDataset(metadata_train_val, preprocessor, ROOT, class_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "39d0ebfb-50ad-42d7-a0f8-c60674d1625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CloudDataTrainLoader = DataLoader(cloud_train_dataset, batch_size=32, shuffle=True)\n",
    "CloudDataValLoader = DataLoader(cloud_val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "20e77f2b-39e0-46b5-851d-d5ca42b8501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d72c83e3-b3b8-4d21-acf3-a51844220867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "def get_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'f1_score':f1_score(y_true, y_pred, average='macro',zero_division = 0),\n",
    "        'precision':precision_score(y_true, y_pred, average='macro',zero_division = 0),\n",
    "        'recall':recall_score(y_true, y_pred, average='macro',zero_division = 0),\n",
    "        'balanced_acc':balanced_accuracy_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "def load_data(data):\n",
    "    X,y = data['data'], data['category']\n",
    "    X = torch.transpose(X.float(),1,2)\n",
    "    return X, y\n",
    "\n",
    "def perform_optimisation(optimiser, model, loss_fn, X, y):\n",
    "    optimiser.zero_grad()\n",
    "    model_output = model(X)\n",
    "    loss = loss_fn(model_output, y)\n",
    "    loss.backward()\n",
    "    optimiser.step() \n",
    "    return loss\n",
    "\n",
    "def reporting(batch_print, running_loss):\n",
    "    last_loss = running_loss / batch_print # average loss per batch\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "070f4fc5-0865-4f38-93dc-d129a5e898e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8c606724-a632-4251-a5e4-b63571a63503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b421fcd5d0a4996b6ababaf04fa9bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.77838659286499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced3da50be0242d38a4afaaa1061164b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.893237829208374\n",
      "2.8395321369171143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f49945d248947f8aac66e5e200b68e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.866215944290161\n",
      "2.830862522125244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4bf9aae4ec440a8497f9cbcb81effe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7969491481781006\n",
      "3.1443512439727783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afc139a9178401b8040f6b54a8edd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7825820446014404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a125e234e74d3696a1b959d4876831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7734, grad_fn=<NllLossBackward0>)\n",
      "{'f1_score': 0.055677655677655674, 'precision': 0.07692307692307693, 'recall': 0.04362801377726751, 'balanced_acc': 0.5671641791044776}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "last_loss = 0\n",
    "epoch_index = 0\n",
    "tracker = []\n",
    "batch_print = 1\n",
    "for i,x in notebook.tqdm(enumerate(CloudDataTrainLoader), total=len(CloudDataTrainLoader)):\n",
    "    # load data\n",
    "    X,y = load_data(x)\n",
    "    loss = perform_optimisation(optimiser, model, loss_fn, X, y)\n",
    "    running_loss += loss.item()\n",
    "    if i % batch_print == 0 and i!=0:\n",
    "        last_loss = reporting(batch_print, running_loss)\n",
    "        print(last_loss)\n",
    "        running_loss = 0\n",
    "\n",
    "        #validate\n",
    "        all_true_output = []\n",
    "        all_model_output = []\n",
    "        for i,x in notebook.tqdm(enumerate(CloudDataValLoader), total=len(CloudDataValLoader)):\n",
    "            # load data\n",
    "            X,y = load_data(x)\n",
    "            model_output = model(X)\n",
    "            all_true_output.append(y)\n",
    "            all_model_output.append(model_output)\n",
    "\n",
    "        all_true = torch.concat(all_true_output)\n",
    "        all_model = torch.concat(all_model_output)\n",
    "        loss = loss_fn(all_model, all_true)\n",
    "        print(loss.item())\n",
    "\n",
    "\n",
    "#validate\n",
    "all_true_output = []\n",
    "all_model_output = []\n",
    "for i,x in notebook.tqdm(enumerate(CloudDataValLoader), total=len(CloudDataValLoader)):\n",
    "    # load data\n",
    "    X,y = load_data(x)\n",
    "    model_output = model(X)\n",
    "    all_true_output.append(y)\n",
    "    all_model_output.append(model_output)\n",
    "\n",
    "all_true = torch.concat(all_true_output)\n",
    "all_model = torch.concat(all_model_output)\n",
    "loss = loss_fn(all_model, all_true)\n",
    "print(loss)\n",
    "classification_output = torch.argmax(torch.exp(all_model),axis = 1)\n",
    "results = get_metrics(all_true, classification_output)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917e45b-3fea-41b7-b71a-8d3763561972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
